{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22bb73eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as Adam\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b3dfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (26708, 2)\n",
      "                                            headline  is_sarcastic\n",
      "0  former versace store clerk sues over secret 'b...             0\n",
      "1  the 'roseanne' revival catches up to our thorn...             0\n",
      "2  mom starting to fear son's web series closest ...             1\n",
      "3  boehner just wants wife to listen, not come up...             1\n",
      "4  j.k. rowling wishes snape happy birthday in th...             0\n"
     ]
    }
   ],
   "source": [
    "# data_df= pd.read_json('C:/Users/nihal/Downloads/archive (1)/Sarcasm_Headlines_Dataset.json', lines=True)\n",
    "# data_df.dropna(inplace=True)\n",
    "# data_df.drop_duplicates(inplace=True)\n",
    "# data_df.drop((\"article_link\"), axis=1, inplace=True)\n",
    "# print(f\"Dataset shape: {data_df.shape}\")\n",
    "# print(data_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ac9e64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size:  18695 which is  70.0 % of total data\n",
      "Validation Size:  4006 which is  15.0 % of total data\n",
      "Testing Size:  4007 which is  15.0 % of total data\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test= train_test_split(np.array(data_df['headline']), np.array(data_df['is_sarcastic']), test_size=0.3)\n",
    "X_val,X_test,y_val,y_test= train_test_split(X_test, y_test, test_size=0.5)\n",
    "print(\"Training Size: \", X_train.shape[0], \"which is \", round(X_train.shape[0]/data_df.shape[0],4)*100, \"% of total data\")\n",
    "print(\"Validation Size: \", X_val.shape[0], \"which is \", round(X_val.shape[0]/data_df.shape[0],4)*100, \"% of total data\")\n",
    "print(\"Testing Size: \", X_test.shape[0], \"which is \", round(X_test.shape[0]/data_df.shape[0],4)*100, \"% of total data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "765106d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2cb65cd73d46a281b2c9c20dcd86f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nihal\\OneDrive\\Desktop\\python-codes\\cudenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\nihal\\.cache\\huggingface\\hub\\models--google-bert--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6783c80b957428b8d1d21d61517cbb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c4d10b996247b1822c8b91c02f93bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00fdee4173eb46b8baf83ac77683bde0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e2070b91fa4d91a05a358aa4a46984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "bert_model = AutoModel.from_pretrained(\"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10c8bffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self,X,Y):\n",
    "        self.X = [tokenizer(X,\n",
    "                  max_length=100,\n",
    "                  padding='max_length',\n",
    "                  return_tensors='pt',).to(device) \n",
    "                  for X in X\n",
    "        ]\n",
    "        self.Y=torch.tensor(Y,dtype=torch.float32).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "    \n",
    "train_dataset= dataset(X_train,y_train)\n",
    "val_dataset= dataset(X_val,y_val)   \n",
    "test_dataset= dataset(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c3c4bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "EPOCHS=15\n",
    "LR=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff8d5742",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader= DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader= DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader= DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
